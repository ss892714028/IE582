{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from TLU import TLU\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "and_data = pd.read_csv('./and.csv', header=None).to_numpy()\n",
    "or_data = pd.read_csv('./or.csv', header=None).to_numpy()\n",
    "xor_data = pd.read_csv('./xor.csv', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | weights: [0. 0.] | theta: 0.5\n",
      "step: 1 | weights: [0. 0.] | theta: 0.5\n",
      "step: 2 | weights: [0. 0.] | theta: 0.5\n",
      "step: 3 | weights: [0.1 0.1] | theta: 0.4\n",
      "step: 4 | weights: [0.1 0.1] | theta: 0.4\n",
      "step: 5 | weights: [0.1 0.1] | theta: 0.4\n",
      "step: 6 | weights: [0.1 0.1] | theta: 0.4\n",
      "step: 7 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 8 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 9 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 10 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 11 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 12 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 13 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 14 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 15 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 16 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 17 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 18 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 19 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 20 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 21 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 22 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 23 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 24 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 25 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 26 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 27 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 28 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 29 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 30 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 31 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 32 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 33 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 34 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 35 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 36 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 37 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 38 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 39 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 40 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 41 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 42 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 43 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 44 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 45 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 46 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 47 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 48 | weights: [0.2 0.2] | theta: 0.3\n",
      "step: 49 | weights: [0.2 0.2] | theta: 0.3\n"
     ]
    }
   ],
   "source": [
    "model_and = TLU(and_data[:, :2], and_data[:, 2], alpha=0.1, epoch=1)\n",
    "w_and = model_and.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | weights: [0. 0.] | theta: 0.5\n",
      "step: 1 | weights: [0.  0.1] | theta: 0.4\n",
      "step: 2 | weights: [0.1 0.1] | theta: 0.3\n",
      "step: 3 | weights: [0.2 0.2] | theta: 0.2\n",
      "step: 4 | weights: [0.2 0.2] | theta: 0.2\n",
      "step: 5 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 6 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 7 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 8 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 9 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 10 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 11 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 12 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 13 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 14 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 15 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 16 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 17 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 18 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 19 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 20 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 21 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 22 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 23 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 24 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 25 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 26 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 27 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 28 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 29 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 30 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 31 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 32 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 33 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 34 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 35 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 36 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 37 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 38 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 39 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 40 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 41 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 42 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 43 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 44 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 45 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 46 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 47 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 48 | weights: [0.2 0.3] | theta: 0.1\n",
      "step: 49 | weights: [0.2 0.3] | theta: 0.1\n"
     ]
    }
   ],
   "source": [
    "model_or = TLU(or_data[:, :2], or_data[:, 2], alpha=0.1, epoch=1)\n",
    "w_or = model_or.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | weights: [0. 0.] | theta: 0.5\n",
      "step: 1 | weights: [0.  0.1] | theta: 0.4\n",
      "step: 2 | weights: [0.1 0.1] | theta: 0.3\n",
      "step: 3 | weights: [0.1 0.1] | theta: 0.3\n",
      "step: 4 | weights: [0.1 0.1] | theta: 0.3\n",
      "step: 5 | weights: [0.1 0.2] | theta: 0.2\n",
      "step: 6 | weights: [0.2 0.2] | theta: 0.1\n",
      "step: 7 | weights: [0.1 0.1] | theta: 0.2\n",
      "step: 8 | weights: [0.1 0.1] | theta: 0.2\n",
      "step: 9 | weights: [0.1 0.2] | theta: 0.1\n",
      "step: 10 | weights: [0.2 0.2] | theta: 0.0\n",
      "step: 11 | weights: [0.1 0.1] | theta: 0.1\n",
      "step: 12 | weights: [0.1 0.1] | theta: 0.1\n",
      "step: 13 | weights: [0.1 0.2] | theta: 0.0\n",
      "step: 14 | weights: [0.1 0.2] | theta: 0.0\n",
      "step: 15 | weights: [0.  0.1] | theta: 0.1\n",
      "step: 16 | weights: [0.  0.1] | theta: 0.1\n",
      "step: 17 | weights: [0.  0.2] | theta: 0.0\n",
      "step: 18 | weights: [0.1 0.2] | theta: -0.1\n",
      "step: 19 | weights: [0.  0.1] | theta: 0.0\n",
      "step: 20 | weights: [0.  0.1] | theta: 0.0\n",
      "step: 21 | weights: [0.  0.1] | theta: 0.0\n",
      "step: 22 | weights: [0.1 0.1] | theta: -0.1\n",
      "step: 23 | weights: [0. 0.] | theta: 0.0\n",
      "step: 24 | weights: [0. 0.] | theta: 0.0\n",
      "step: 25 | weights: [0.  0.1] | theta: -0.1\n",
      "step: 26 | weights: [0.  0.1] | theta: -0.1\n",
      "step: 27 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 28 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 29 | weights: [-0.1  0.1] | theta: -0.1\n",
      "step: 30 | weights: [0.  0.1] | theta: -0.2\n",
      "step: 31 | weights: [-0.1  0. ] | theta: -0.1\n",
      "step: 32 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 33 | weights: [-0.1  0.1] | theta: -0.1\n",
      "step: 34 | weights: [0.  0.1] | theta: -0.2\n",
      "step: 35 | weights: [-0.1  0. ] | theta: -0.1\n",
      "step: 36 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 37 | weights: [-0.1  0.1] | theta: -0.1\n",
      "step: 38 | weights: [0.  0.1] | theta: -0.2\n",
      "step: 39 | weights: [-0.1  0. ] | theta: -0.1\n",
      "step: 40 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 41 | weights: [-0.1  0.1] | theta: -0.1\n",
      "step: 42 | weights: [0.  0.1] | theta: -0.2\n",
      "step: 43 | weights: [-0.1  0. ] | theta: -0.1\n",
      "step: 44 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 45 | weights: [-0.1  0.1] | theta: -0.1\n",
      "step: 46 | weights: [0.  0.1] | theta: -0.2\n",
      "step: 47 | weights: [-0.1  0. ] | theta: -0.1\n",
      "step: 48 | weights: [-0.1  0. ] | theta: 0.0\n",
      "step: 49 | weights: [-0.1  0.1] | theta: -0.1\n"
     ]
    }
   ],
   "source": [
    "model_xor = TLU(xor_data[:, :2], xor_data[:, 2], alpha=0.1, epoch=1)\n",
    "w_xor = model_xor.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for and gate\n",
    "model_and.test(w_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for or gate\n",
    "model_or.test(w_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy for xor gate\n",
    "model_xor.test(w_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For and gate and or gate, it is easy to see that the model converges. After a few steps, weights stays constant, which means that the model does not make any wrong prediction of the label.  \n",
    "The xor gate does not converge with TLU since TLU is a linear approximator, but there exists no linear hyperplane that can separate the two classes of xor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_boundary(pred_func,X,y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.15, X[:, 0].max() + 0.15\n",
    "    y_min, y_max = X[:, 1].min() - 0.15, X[:, 1].max() + 0.15\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y,s=100)\n",
    "    plt.show()\n",
    "x,y = xor_data[:, :2], xor_data[:, 2]    \n",
    "clf = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(32),\\\n",
    "                    activation=\"logistic\", random_state=1,max_iter=10000)\n",
    "clf.fit(x[:4], y[:4])\n",
    "plt.figure(figsize=(8,8))\n",
    "plot_decision_boundary(lambda x: clf.predict(x), x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TLU:\n",
    "    def __init__(self, x, y, alpha, epoch, theta=0.5):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.feature_dim = self.x.shape[1]\n",
    "        self.theta = theta\n",
    "        self.alpha = alpha\n",
    "        self.epoch = epoch\n",
    "\n",
    "    @staticmethod\n",
    "    def add_feature(d):\n",
    "        data = []\n",
    "        for index, value in enumerate(d):\n",
    "            data.append(np.append(d[index], -1))\n",
    "        return np.array(data)\n",
    "\n",
    "    def fit(self):\n",
    "        self.x = self.add_feature(self.x)\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        w = np.zeros(self.x.shape[1])\n",
    "        w[-1] = self.theta\n",
    "        for epochs in range(self.epoch):\n",
    "            for i in range(x.shape[0]):\n",
    "                sample = x[i]\n",
    "                y_hat = self.predict(sample, w)\n",
    "                w += self.alpha * (y[i] - y_hat) * sample\n",
    "                print('step: {} | weights: {} | theta: {}'.format(i, w[:-1], round(w[-1], 3)))\n",
    "        return w\n",
    "\n",
    "    @staticmethod\n",
    "    def predict(x, w):\n",
    "        dot = np.dot(w, x)\n",
    "        if dot >= 0:\n",
    "            y_hat = 1\n",
    "        else:\n",
    "            y_hat = 0\n",
    "        return y_hat\n",
    "\n",
    "    def test(self, w):\n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        error = 0\n",
    "        for i in range(self.x.shape[0]):\n",
    "            y_hat = self.predict(x[i], w)\n",
    "            if y_hat != y[i]:\n",
    "                error += 1\n",
    "        accuracy = 1-error/len(y)\n",
    "        return accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
